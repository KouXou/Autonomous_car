{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import glob\n",
    "import PIL.Image\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "FILES_PATH='/home/kostas/Autonomous_car/files/'\n",
    "\n",
    "track_name = 'track5'\n",
    "PARENT_PATH= FILES_PATH + track_name + '/' + 'direction1_50'\n",
    "speed_value = 75\n",
    "data_dirs=['direction1_75','direction2_75']\n",
    "class_names = ['forward', 'stop', 'forward_left', 'forward_right']\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "class Directory:\n",
    "    def __init__(self, parent_path):\n",
    "        self.parent_path = parent_path\n",
    "\n",
    "    def getSubdirectories(self):\n",
    "        return [dI for dI in os.listdir(self.parent_path) if os.path.isdir(os.path.join(self.parent_path,dI))]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "class ImageLoader:\n",
    "    def __init__(self, parent_dir_path=''):\n",
    "        self.parent_dir_path = parent_dir_path\n",
    "\n",
    "    def load_image_paths(self):\n",
    "        return glob.glob(self.parent_dir_path + '/*.jpg')\n",
    "\n",
    "\n",
    "    def load_image(self, img_path, resize=True):\n",
    "\n",
    "        img = PIL.Image.open(img_path)\n",
    "        if resize:\n",
    "            img = transforms.functional.resize(img, (224, 224))\n",
    "\n",
    "        img = transforms.functional.to_tensor(img)\n",
    "        img = transforms.functional.normalize(img, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        return img\n",
    "\n",
    "    def transformImage(self, image):\n",
    "        image = transforms.functional.resize(image, (480, 640))\n",
    "        image = transforms.functional.to_tensor(image)\n",
    "        return image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "class CsvLoader:\n",
    "    def __init__(self, parent_dir_path=''):\n",
    "        self.parent_dir_path = parent_dir_path\n",
    "\n",
    "    def load_csv_path(self):\n",
    "        return glob.glob(self.parent_dir_path + '/*.csv')\n",
    "\n",
    "    def load_csv_to_df(self, csv_path):\n",
    "        return pd.read_csv(csv_path, delimiter=',')\n",
    "\n",
    "    def map_class_to_int(self, df):\n",
    "        idx_to_label = {\n",
    "            'forward':0 , 'stop':1 , 'forward_left':2, 'forward_right':3\n",
    "        }\n",
    "        return df.replace({'Move': idx_to_label})"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "class TrainTestDataSplitter:\n",
    "    def __init__(self, train_batch_size=4, test_batch_size=1):\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.test_batch_size = test_batch_size\n",
    "\n",
    "    def split_images(self, images_tensor):\n",
    "        train_images = []\n",
    "        test_images = []\n",
    "        size = len(images_tensor)\n",
    "        for i in range(size):\n",
    "            if i % 5 == 0:\n",
    "                test_images.append(images_tensor[i])\n",
    "            else:\n",
    "                train_images.append(images_tensor[i])\n",
    "        print(len(train_images), len(test_images))\n",
    "        return train_images, test_images\n",
    "\n",
    "    def split_classes(self, output_classes_torch):\n",
    "        train_classes = []\n",
    "        test_classes = []\n",
    "        size = len(output_classes_torch)\n",
    "        for i in range(size):\n",
    "            if i % 5 == 0:\n",
    "                test_classes.append(output_classes_torch[i])\n",
    "            else:\n",
    "                train_classes.append(output_classes_torch[i])\n",
    "        print(len(train_classes), len(test_classes))\n",
    "        return train_classes, test_classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2021-01-02_14-29-02', '2021-01-02_14-29-48', '2021-01-02_14-31-03', '2021-01-02_14-31-43', '2021-01-02_14-32-22', '2021-01-02_14-32-50', '2021-01-02_14-34-54', '2021-01-02_14-36-34', '2021-01-02_14-37-08', '2021-01-02_14-37-46', '2021-01-02_14-38-23', '2021-01-02_14-39-06', '2021-01-02_14-40-18']\n"
     ]
    }
   ],
   "source": [
    "parent_directory = Directory(PARENT_PATH)\n",
    "\n",
    "subdirectories = parent_directory.getSubdirectories()\n",
    "print(sorted(subdirectories))\n",
    "\n",
    "all_image_paths= []\n",
    "all_csv_paths = []\n",
    "for subdirectory in sorted(subdirectories):\n",
    "    subdirectory_path = PARENT_PATH + '/' + subdirectory\n",
    "    imageLoader = ImageLoader(subdirectory_path)\n",
    "    image_paths = imageLoader.load_image_paths()\n",
    "    image_paths.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
    "    all_image_paths += image_paths\n",
    "\n",
    "    csvLoader = CsvLoader(subdirectory_path)\n",
    "    csvPath = csvLoader.load_csv_path()\n",
    "    all_csv_paths += csvPath\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5390\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(all_image_paths))\n",
    "print(len(all_csv_paths))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kostas/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5390\n"
     ]
    }
   ],
   "source": [
    "im = ImageLoader()\n",
    "images =  [torch.tensor(im.load_image(path)) for path in all_image_paths]\n",
    "\n",
    "print(len(images))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "cl= CsvLoader()\n",
    "\n",
    "output_classes = np.zeros(0)\n",
    "for path in all_csv_paths:\n",
    "    csv = cl.load_csv_to_df(path)\n",
    "    data_classes = cl.map_class_to_int(csv)['Move'] # .astype('int64')\n",
    "    output_classes = np.concatenate((output_classes,data_classes), axis=0)\n",
    "\n",
    "print(output_classes)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        ...,\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 1., 0., 0.]])"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "output_classes_tensor = torch.tensor(output_classes,  dtype=torch.int64)\n",
    "\n",
    "target_onehot = torch.zeros(output_classes_tensor.shape[0], 4)\n",
    "target_onehot.scatter_(1, output_classes_tensor.unsqueeze(1), 1.0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4312 1078\n",
      "4312 1078\n"
     ]
    }
   ],
   "source": [
    "splitter = TrainTestDataSplitter(4,1)\n",
    "train_images, test_images = splitter.split_images(images)\n",
    "train_classes, test_classes = splitter.split_classes(output_classes)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([[[ 0.9132,  0.8618,  0.8447,  ..., -0.1999, -0.1486, -0.1314],\n          [ 0.8961,  0.8447,  0.7933,  ..., -0.1828, -0.1486, -0.1657],\n          [ 0.8789,  0.8276,  0.7933,  ..., -0.1314, -0.1314, -0.1657],\n          ...,\n          [ 0.3994,  0.3823,  0.3652,  ..., -1.5185, -1.5014, -1.4500],\n          [ 0.3652,  0.3823,  0.3823,  ..., -1.5014, -1.5185, -1.4500],\n          [ 0.3994,  0.4166,  0.4337,  ..., -1.4329, -1.4500, -1.3987]],\n \n         [[-0.3375, -0.3375, -0.3375,  ..., -0.8803, -0.8803, -0.8627],\n          [-0.3550, -0.3550, -0.3375,  ..., -0.8627, -0.8803, -0.8978],\n          [-0.3200, -0.3550, -0.3375,  ..., -0.8102, -0.8627, -0.8978],\n          ...,\n          [-0.5476, -0.5476, -0.5301,  ..., -2.0357, -2.0182, -1.9657],\n          [-0.5651, -0.5476, -0.5126,  ..., -2.0357, -2.0357, -1.9832],\n          [-0.5301, -0.5126, -0.4601,  ..., -1.9657, -1.9832, -1.9307]],\n \n         [[ 0.0779,  0.0605,  0.0953,  ..., -0.6193, -0.6018, -0.5844],\n          [ 0.0605,  0.0431,  0.0779,  ..., -0.6018, -0.6018, -0.6193],\n          [ 0.0779,  0.0431,  0.0431,  ..., -0.5495, -0.5844, -0.6193],\n          ...,\n          [-0.2358, -0.2358, -0.2010,  ..., -1.6476, -1.6650, -1.6127],\n          [-0.2532, -0.2358, -0.1835,  ..., -1.6302, -1.6476, -1.5779],\n          [-0.2184, -0.2010, -0.1312,  ..., -1.5604, -1.5779, -1.5256]]]),\n 0.0)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = [(train_images[i], train_classes[i]) for i in range(len(train_images))]\n",
    "test_data = [(test_images[i], test_classes[i]) for i in range(len(test_images))]\n",
    "train_data[10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4, shuffle=True, num_workers=0)\n",
    "test_loader =  torch.utils.data.DataLoader(test_data, batch_size=4, shuffle=True, num_workers=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(512, len(class_names))\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)\n",
    "            labels = labels.to(device=device, dtype=torch.int64)\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        # if epoch == 1 or epoch % 5 == 0:\n",
    "        print('{} Epoch {}, Training loss {}'.format(\n",
    "            datetime.datetime.now(), epoch,\n",
    "            loss_train / len(train_loader)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-01-02 15:44:14.314589 Epoch 1, Training loss 0.5366479787985917\n",
      "2021-01-02 15:54:15.955117 Epoch 2, Training loss 0.4029280909782894\n",
      "2021-01-02 16:04:29.464301 Epoch 3, Training loss 0.3486081827747254\n",
      "2021-01-02 16:14:47.151083 Epoch 4, Training loss 0.31464093311988717\n",
      "2021-01-02 16:25:19.648729 Epoch 5, Training loss 0.29071583991942856\n",
      "2021-01-02 16:35:52.536326 Epoch 6, Training loss 0.26312967361538914\n",
      "2021-01-02 16:46:26.550088 Epoch 7, Training loss 0.2538468446265059\n",
      "2021-01-02 16:57:02.578911 Epoch 8, Training loss 0.219572668430652\n",
      "2021-01-02 17:07:39.867892 Epoch 9, Training loss 0.1917830487576716\n",
      "2021-01-02 17:18:18.191027 Epoch 10, Training loss 0.16649571656264475\n",
      "2021-01-02 17:28:58.433241 Epoch 11, Training loss 0.1508078682792532\n",
      "2021-01-02 17:39:34.980029 Epoch 12, Training loss 0.12861417167778622\n",
      "2021-01-02 17:50:07.721597 Epoch 13, Training loss 0.11238504408452181\n",
      "2021-01-02 18:00:40.207945 Epoch 14, Training loss 0.09716991763664286\n",
      "2021-01-02 18:11:09.537304 Epoch 15, Training loss 0.0971071918360401\n",
      "2021-01-02 18:21:51.321662 Epoch 16, Training loss 0.07572173494711347\n",
      "2021-01-02 18:32:31.862079 Epoch 17, Training loss 0.05285164068340884\n",
      "2021-01-02 18:43:14.110355 Epoch 18, Training loss 0.06350271804412656\n",
      "2021-01-02 18:53:57.508551 Epoch 19, Training loss 0.05642504668674592\n",
      "2021-01-02 19:04:35.677819 Epoch 20, Training loss 0.05112638468516604\n"
     ]
    }
   ],
   "source": [
    "training_loop(\n",
    "    n_epochs = 20,\n",
    "    optimizer = optimizer,\n",
    "    model = model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), FILES_PATH + 'track5_1_model.pt')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}